{
  "additions": 5,
  "author": {
    "is_bot": true,
    "login": "app/idobata-policy-app"
  },
  "body": "匿名ユーザーさんとの議論に基づき、「１）子ども一人ひとりに「専属のAIアシスタント」を届けます」の項目において、AIのハルシネーション（誤った情報の生成）対策を大幅に強化・具体化する提案です。\n\n**【背景・課題】**\n当初の案では、AIのハルシネーション対策として「AIの役割の限定」「人間の監督・判断」「リテラシー教育」を挙げていましたが、匿名ユーザーさんより、以下の極めて重要なご指摘をいただきました。\n1.  子どもはAIの提示する情報を鵜呑みにしやすく、特に未知の分野では誤りに気づけない危険性が高い。\n2.  AIが出力した情報の妥当性をすべて教員が確認するのでは、教員の負担軽減につながらず、多忙な現場では形骸化する恐れがある。\n3.  AIの誤りは、人間の間違いとは異なり突拍子もない場合があり、チェックが困難なケースも想定される。\n4.  子どもが安易に答えだけを求めてしまい、情報を精査する態度が育たない可能性がある。\nこれらのご指摘を受け、より踏み込んだ具体的な対策が必要であるとの結論に至りました。\n\n**【具体的な変更内容】**\nAI学習アシスタントの機能について、以下の2点を明確に追記しました。\n\n1.  **参照情報源の限定による信頼性の担保：**\n    AIが参照する情報源を、原則として「学習指導要領に準拠した教科書」や「政府・教育委員会が承認した教材・資料」に限定します。これにより、AIが生成する回答の信頼性を根本から担保し、子どもが誤った情報や偏った見解に触れるリスクを最小化します。また、教員が都度ファクトチェックを行う負担を大幅に軽減します。\n\n2.  **探究心を育む「探究のパートナー」としての役割：**\n    承認された教材の範囲を超える発展的な問いが子どもから投げかけられた場合、AIは単に「わからない」と応答するのではなく、「素晴らしい質問だね」とまず肯定的に受け止めます。その上で、信頼できる情報の探し方（例：図書館の利用、信頼性の高いWebサイトの見分け方）や、先生への効果的な質問の仕方を一緒に考える「探究のパートナー」として機能します。これにより、子どもの知的好奇心や探究心を削ぐことなく、安全な環境で自ら学ぶ力を育むことを目指します。\n\n**【この改善の目的と意図】**\nこの改善は、教育現場へのAI導入における最大の懸念の一つであるハルシネーション問題に対し、技術的・運用的な側面から具体的な解決策を示すものです。単にリスクを回避するだけでなく、その制約を逆手に取り、子どもの主体的な学習態度や情報リテラシーを育むための仕組みへと昇華させることを意図しています。匿名ユーザーさんの「私が子供だったらちょっとがっかりしそう」という感性豊かな視点から生まれたこのアイデアは、AIを単なる知識提供ツールではなく、子どもの学びに伴走する真のパートナーと位置づけるための重要な一歩となると考えます。",
  "changedFiles": 1,
  "comments": [],
  "createdAt": "2025-07-12T09:00:44Z",
  "deletions": 3,
  "labels": [
    {
      "id": "LA_kwDOOqTJvM8AAAACAn5d8w",
      "name": "教育",
      "description": "",
      "color": "E57B81"
    }
  ],
  "mergeable": "MERGEABLE",
  "mergedAt": null,
  "number": 5747,
  "reactionGroups": [],
  "state": "OPEN",
  "title": "「AI学習アシスタント」のハルシネーション対策の具体化と探究心を引き出す仕組みの提案",
  "updatedAt": "2025-07-12T15:19:40Z",
  "url": "https://github.com/team-mirai/policy/pull/5747",
  "commentsCount": 0,
  "totalReactions": 0
}