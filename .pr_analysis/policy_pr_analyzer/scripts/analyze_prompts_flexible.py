#!/usr/bin/env python3
"""
ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¤‡æ•°ã®APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å®Ÿè¡Œã—ã¦åˆ†æã‚’è¡Œã†
"""

import os
import sys
import argparse
import subprocess
import time
import json
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class APIProvider:
    """APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.name = "base"

    def analyze(self, prompt_content):
        """åˆ†æã‚’å®Ÿè¡Œã™ã‚‹"""
        raise NotImplementedError

    def is_available(self):
        """ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return False


class ClaudeCLIProvider(APIProvider):
    """Claude CLI (claude -p) ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""

    def __init__(self):
        super().__init__()
        self.name = "claude-cli"

    def analyze(self, prompt_content):
        """claude -pã‚³ãƒãƒ³ãƒ‰ã§åˆ†æ"""
        try:
            result = subprocess.run(
                ["claude", "-p"],
                input=prompt_content,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                return None, f"Error: {result.stderr}"

            return result.stdout, None
        except Exception as e:
            return None, f"Exception: {e}"

    def is_available(self):
        """claude ã‚³ãƒãƒ³ãƒ‰ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                ["claude", "--version"], capture_output=True)
            return result.returncode == 0
        except:
            return False


class AnthropicAPIProvider(APIProvider):
    """Anthropic API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""

    def __init__(self):
        super().__init__()
        self.name = "anthropic"
        self.client = None
        if ANTHROPIC_AVAILABLE:
            try:
                self.client = anthropic.Anthropic()
            except Exception as e:
                print(f"Warning: Failed to initialize Anthropic client: {e}")

    def analyze(self, prompt_content):
        """Anthropic APIã§åˆ†æ"""
        if not self.client:
            return None, "Anthropic client not initialized"

        try:
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                temperature=0,
                messages=[
                    {"role": "user", "content": prompt_content}
                ]
            )

            return response.content[0].text, None
        except anthropic.RateLimitError as e:
            return None, f"Rate limit error: {e}"
        except Exception as e:
            return None, f"API error: {e}"

    def is_available(self):
        """Anthropic APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return ANTHROPIC_AVAILABLE and self.client is not None


class OpenAIAPIProvider(APIProvider):
    """OpenAI API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""

    def __init__(self):
        super().__init__()
        self.name = "openai"
        self.client = None
        if OPENAI_AVAILABLE:
            try:
                self.client = openai.OpenAI()
            except Exception as e:
                print(f"Warning: Failed to initialize OpenAI client: {e}")

    def analyze(self, prompt_content):
        """OpenAI APIã§åˆ†æ"""
        if not self.client:
            return None, "OpenAI client not initialized"

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                max_tokens=4000,
                temperature=0,
                messages=[
                    {"role": "user", "content": prompt_content}
                ]
            )

            return response.choices[0].message.content, None
        except openai.RateLimitError as e:
            return None, f"Rate limit error: {e}"
        except Exception as e:
            return None, f"API error: {e}"

    def is_available(self):
        """OpenAI APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return OPENAI_AVAILABLE and self.client is not None


def get_provider(provider_name):
    """æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—"""
    providers = {
        "claude-cli": ClaudeCLIProvider(),
        "anthropic": AnthropicAPIProvider(),
        "openai": OpenAIAPIProvider()
    }

    if provider_name not in providers:
        available = list(providers.keys())
        raise ValueError(
            f"Unknown provider: {provider_name}. Available: {available}")

    provider = providers[provider_name]
    if not provider.is_available():
        raise ValueError(f"Provider {provider_name} is not available")

    return provider


def run_analysis_with_retry(prompt_file, output_file, provider, dry_run=False, max_retries=3):
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§åˆ†æã‚’å®Ÿè¡Œ"""
    if dry_run:
        print(f"  [DRY RUN] Would analyze: {prompt_file} -> {output_file}")
        return True

    try:
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with open(prompt_file, 'r', encoding='utf-8') as f:
            prompt_content = f.read()

        # ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
        for attempt in range(max_retries):
            result, error = provider.analyze(prompt_content)

            if result is not None:
                # çµæœã‚’ä¿å­˜
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(result)

                print(
                    f"  âœ… Analyzed: {os.path.basename(prompt_file)} (using {provider.name})")
                return True

            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            if "rate limit" in error.lower():
                print(
                    f"  â±ï¸ Rate limit hit for {os.path.basename(prompt_file)}, attempt {attempt + 1}/{max_retries}")
                if attempt < max_retries - 1:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    wait_time = 60 * (2 ** attempt)
                    print(f"  â³ Waiting {wait_time} seconds before retry...")
                    time.sleep(wait_time)
                else:
                    print(
                        f"  âŒ Max retries reached for {os.path.basename(prompt_file)}")
                    return False
            else:
                print(f"  âŒ Error: {error}")
                return False

        return False

    except Exception as e:
        print(f"  âŒ Exception: {e}")
        return False


def get_analysis_status(prompts_dir):
    """åˆ†æã®é€²æ—çŠ¶æ³ã‚’ç¢ºèª"""
    status = {
        'individual': {'total': 0, 'completed': 0, 'files': []},
        'similarity': {'total': 0, 'completed': 0, 'files': []},
        'trend': {'total': 0, 'completed': 0, 'files': []}
    }

    for analysis_type in ['individual', 'similarity', 'trend']:
        input_dir = Path(prompts_dir) / analysis_type
        output_dir = Path(prompts_dir) / 'output' / analysis_type

        if input_dir.exists():
            input_files = list(input_dir.glob('*.txt'))
            status[analysis_type]['total'] = len(input_files)

            for input_file in input_files:
                output_file = output_dir / input_file.with_suffix('.json').name
                if output_file.exists():
                    status[analysis_type]['completed'] += 1
                else:
                    status[analysis_type]['files'].append(input_file)

    return status


def analyze_individual_prs(prompts_dir, provider, sleep_time=2, dry_run=False, resume=True, max_workers=3):
    """å€‹åˆ¥PRåˆ†æã‚’å®Ÿè¡Œï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰"""
    input_dir = Path(prompts_dir) / 'individual'
    output_dir = Path(prompts_dir) / 'output' / 'individual'

    if not input_dir.exists():
        print("âŒ Individual prompts directory not found")
        return 0, 0

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    prompt_files = sorted(input_dir.glob('*.txt'))

    # åˆ†æãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’æŠ½å‡º
    files_to_analyze = []
    skipped = 0

    for prompt_file in prompt_files:
        output_file = output_dir / prompt_file.with_suffix('.json').name
        if resume and output_file.exists():
            skipped += 1
        else:
            files_to_analyze.append((prompt_file, output_file))

    total = len(prompt_files)
    total_to_analyze = len(files_to_analyze)

    print(
        f"\n=== Analyzing Individual PRs ({total} files, {total_to_analyze} remaining) ===")
    print(f"Using {max_workers} parallel workers with {provider.name} provider")

    if dry_run:
        for i, (prompt_file, output_file) in enumerate(files_to_analyze):
            print(f"[{i+1}/{total_to_analyze}] Would analyze: {prompt_file.name}")
        return total_to_analyze, skipped

    completed = 0

    def analyze_single_file(file_info):
        prompt_file, output_file = file_info
        try:
            if run_analysis_with_retry(prompt_file, output_file, provider, dry_run=False):
                return prompt_file.name, True, None
            else:
                return prompt_file.name, False, "Analysis failed"
        except Exception as e:
            return prompt_file.name, False, str(e)

    # ä¸¦åˆ—å®Ÿè¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
        future_to_file = {executor.submit(
            analyze_single_file, file_info): file_info for file_info in files_to_analyze}

        # çµæœã‚’å‡¦ç†
        for future in as_completed(future_to_file):
            file_info = future_to_file[future]
            prompt_file, output_file = file_info

            try:
                filename, success, error = future.result()
                completed_now = completed + 1
                if success:
                    print(
                        f"[{completed_now}/{total_to_analyze}] âœ… Completed: {filename}")
                    completed += 1
                else:
                    print(
                        f"[{completed_now}/{total_to_analyze}] âŒ Failed: {filename} - {error}")
            except Exception as e:
                print(f"âŒ Exception analyzing {prompt_file.name}: {e}")

            # ã‚¹ãƒªãƒ¼ãƒ—ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
            if provider.name in ['anthropic', 'openai']:
                time.sleep(sleep_time)
            elif provider.name == 'claude-cli':
                time.sleep(sleep_time / max_workers)

    return completed, skipped


def analyze_similarity_checks(prompts_dir, provider, sleep_time=2, dry_run=False, resume=True, limit=None):
    """é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
    input_dir = Path(prompts_dir) / 'similarity'
    output_dir = Path(prompts_dir) / 'output' / 'similarity'

    if not input_dir.exists():
        print("âŒ Similarity prompts directory not found")
        return 0, 0

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    prompt_files = sorted(input_dir.glob('*.txt'))
    if limit:
        prompt_files = prompt_files[:limit]

    total = len(prompt_files)
    completed = 0
    skipped = 0

    print(f"\n=== Analyzing Similarity Checks ({total} files) ===")
    print(f"Using {provider.name} provider")

    for i, prompt_file in enumerate(prompt_files):
        output_file = output_dir / prompt_file.with_suffix('.json').name

        # æ—¢ã«åˆ†ææ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if resume and output_file.exists():
            print(f"[{i+1}/{total}] Skipping (already analyzed): {prompt_file.name}")
            skipped += 1
            continue

        print(f"[{i+1}/{total}] Analyzing: {prompt_file.name}")

        if run_analysis_with_retry(prompt_file, output_file, provider, dry_run):
            completed += 1

        # æœ€å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ã¯ã‚¹ãƒªãƒ¼ãƒ—
        if i < total - 1 and not dry_run:
            time.sleep(sleep_time)

    return completed, skipped


def analyze_trend(prompts_dir, provider, dry_run=False):
    """å…¨ä½“å‚¾å‘åˆ†æã‚’å®Ÿè¡Œ"""
    input_file = Path(prompts_dir) / 'trend' / 'overall_trend_analysis.txt'
    output_file = Path(prompts_dir) / 'output' / 'trend' / \
        'overall_trend_analysis.json'

    if not input_file.exists():
        print("âŒ Trend analysis prompt not found")
        return False

    print(f"\n=== Analyzing Overall Trend ===")
    print(f"Using {provider.name} provider")
    print(f"Analyzing: {input_file.name}")

    return run_analysis_with_retry(input_file, output_file, provider, dry_run)


def main():
    parser = argparse.ArgumentParser(
        description='Run analysis on generated prompts with multiple API providers')
    parser.add_argument(
        'prompts_dir', help='Directory containing the prompts (e.g., prompts/batch_50)')
    parser.add_argument('--api-provider', choices=['claude-cli', 'anthropic', 'openai'],
                        default='claude-cli', help='API provider to use (default: claude-cli)')
    parser.add_argument('--type', choices=['all', 'individual', 'similarity', 'trend'],
                        default='all', help='Type of analysis to run (default: all)')
    parser.add_argument('--sleep', type=float, default=2,
                        help='Sleep time between analyses in seconds (default: 2)')
    parser.add_argument('--dry-run', action='store_true',
                        help='Show what would be done without actually running')
    parser.add_argument('--no-resume', action='store_true',
                        help='Re-analyze all files (don\'t skip existing ones)')
    parser.add_argument('--similarity-limit', type=int,
                        help='Limit number of similarity checks to run')
    parser.add_argument('--status', action='store_true',
                        help='Show analysis status and exit')
    parser.add_argument('--workers', type=int, default=3,
                        help='Number of parallel workers for analysis (default: 3)')

    args = parser.parse_args()

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    if args.status:
        status = get_analysis_status(args.prompts_dir)
        print("\n=== Analysis Status ===")
        for analysis_type, info in status.items():
            print(f"\n{analysis_type.capitalize()}:")
            print(f"  Total: {info['total']}")
            print(f"  Completed: {info['completed']}")
            print(f"  Remaining: {info['total'] - info['completed']}")
        sys.exit(0)

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–
    try:
        provider = get_provider(args.api_provider)
        print(f"âœ… Using {provider.name} provider")
    except ValueError as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® sleep æ™‚é–“ã‚’ API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ã¦èª¿æ•´
    if args.sleep == 2:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã®ã¿èª¿æ•´
        if args.api_provider in ['anthropic', 'openai']:
            args.sleep = 10  # API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å ´åˆã¯é•·ã‚ã«
        elif args.api_provider == 'claude-cli':
            args.sleep = 2   # claude-cli ã®å ´åˆã¯çŸ­ã‚ã«

    # ä¸¦åˆ—æ•°ã‚’ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ã¦èª¿æ•´
    if args.workers == 3:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã®ã¿èª¿æ•´
        if args.api_provider in ['anthropic', 'openai']:
            args.workers = 1  # API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å ´åˆã¯1ã¤ãšã¤
        elif args.api_provider == 'claude-cli':
            args.workers = 3  # claude-cli ã®å ´åˆã¯ä¸¦åˆ—å®Ÿè¡Œ

    resume = not args.no_resume
    start_time = datetime.now()

    print(f"Starting analysis at {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Prompts directory: {args.prompts_dir}")
    print(f"Resume mode: {resume}")
    print(f"Parallel workers: {args.workers}")
    print(f"Sleep time: {args.sleep} seconds")
    if args.dry_run:
        print("ğŸ” DRY RUN MODE - No actual analysis will be performed")

    results = {
        'individual': {'completed': 0, 'skipped': 0},
        'similarity': {'completed': 0, 'skipped': 0},
        'trend': {'completed': 0}
    }

    # å€‹åˆ¥PRåˆ†æ
    if args.type in ['all', 'individual']:
        completed, skipped = analyze_individual_prs(
            args.prompts_dir, provider, args.sleep, args.dry_run, resume, args.workers
        )
        results['individual']['completed'] = completed
        results['individual']['skipped'] = skipped

    # é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
    if args.type in ['all', 'similarity']:
        completed, skipped = analyze_similarity_checks(
            args.prompts_dir, provider, args.sleep, args.dry_run, resume, args.similarity_limit
        )
        results['similarity']['completed'] = completed
        results['similarity']['skipped'] = skipped

    # å…¨ä½“å‚¾å‘åˆ†æ
    if args.type in ['all', 'trend']:
        if analyze_trend(args.prompts_dir, provider, args.dry_run):
            results['trend']['completed'] = 1

    # çµæœã‚µãƒãƒªãƒ¼
    end_time = datetime.now()
    duration = end_time - start_time

    print(f"\n=== Analysis Complete ===")
    print(f"Duration: {duration}")
    print(f"Provider: {provider.name}")
    print(f"\nResults:")
    print(
        f"  Individual PRs: {results['individual']['completed']} analyzed, {results['individual']['skipped']} skipped")
    print(
        f"  Similarity checks: {results['similarity']['completed']} analyzed, {results['similarity']['skipped']} skipped")
    print(f"  Trend analysis: {results['trend']['completed']} completed")

    if not args.dry_run:
        print(f"\nOutput files saved in: {args.prompts_dir}/output/")


if __name__ == "__main__":
    main()
