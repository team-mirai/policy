#!/usr/bin/env python3
import yaml
import json
import subprocess
import time
from typing import List, Dict, Any


def load_yaml_data():
    """YAML ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ PR ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open('readme-pr.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def get_unprocessed_prs(data: Dict[str, Any], limit: int = 80) -> List[Dict[str, Any]]:
    """æœªå‡¦ç†ã® PR ã‚’å–å¾—"""
    unprocessed = []
    for pr in data['pull_requests']:
        if pr.get('label_updated') == False and pr.get('number') != 1998:  # ä¾‹ã®PRã‚’é™¤å¤–
            unprocessed.append(pr)
            if len(unprocessed) >= limit:
                break
    return unprocessed


def get_pr_details(pr_number: int) -> Dict[str, Any]:
    """GitHub API ã‚’ä½¿ã£ã¦ PR ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
    try:
        # PR ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        cmd = f"gh pr view {pr_number} --json title,body,state,author,url,createdAt"
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"âŒ PR #{pr_number} ã®æƒ…å ±å–å¾—ã«å¤±æ•—: {result.stderr}")
            return None

        pr_info = json.loads(result.stdout)

        # PR ã® diff ã‚’å–å¾—
        diff_cmd = f"gh pr diff {pr_number}"
        diff_result = subprocess.run(
            diff_cmd, shell=True, capture_output=True, text=True)

        pr_info['diff'] = diff_result.stdout if diff_result.returncode == 0 else ""

        return pr_info

    except Exception as e:
        print(f"âŒ PR #{pr_number} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def classify_pr(pr_info: Dict[str, Any]) -> tuple[str, str]:
    """PR ã®å†…å®¹ã‚’åˆ†æã—ã¦åˆ†é¡"""
    title = pr_info.get('title', '')
    body = pr_info.get('body', '')
    diff = pr_info.get('diff', '')

    # åˆ†æãƒ­ã‚¸ãƒƒã‚¯
    content = f"{title} {body} {diff}".lower()

    # ã‚·ã‚¹ãƒ†ãƒ é–¢é€£
    if any(keyword in content for keyword in ['readme', 'ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ', 'æ§‹æˆ', 'è¨˜è¿°', 'ã‚·ã‚¹ãƒ†ãƒ ', 'é‹ç”¨', 'github', 'ãƒ—ãƒ­ã‚»ã‚¹']):
        if any(keyword in content for keyword in ['æ”¿ç­–', 'ææ¡ˆ', 'é …ç›®', 'è¿½åŠ ', 'æ”¹é©', 'åˆ¶åº¦']):
            # æ”¿ç­–å†…å®¹ã‚’å«ã‚€å ´åˆã¯è©³ç´°åˆ†æ
            pass
        else:
            return '[ã‚·ã‚¹ãƒ†ãƒ ]', 'ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã®æ§‹æˆã‚„é‹ç”¨ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹ææ¡ˆ'

    # æ•™è‚²é–¢é€£
    if any(keyword in content for keyword in ['æ•™è‚²', 'å­¦æ ¡', 'å­¦ç¿’', 'æ‰èƒ½', 'å¥¨å­¦é‡‘', 'å¤§å­¦', 'å­¦è²»']):
        return 'æ•™è‚²', 'æ•™è‚²åˆ¶åº¦ã‚„å­¦ç¿’ç’°å¢ƒã«é–¢ã™ã‚‹æ”¿ç­–ææ¡ˆ'

    # å­è‚²ã¦é–¢é€£
    if any(keyword in content for keyword in ['å­è‚²ã¦', 'å­ã©ã‚‚', 'å°‘å­åŒ–', 'å…ç«¥', 'ä¿è‚²', 'é¤Šè‚²']):
        return 'å­è‚²ã¦', 'å­è‚²ã¦æ”¯æ´ã‚„å…ç«¥ç¦ç¥‰ã«é–¢ã™ã‚‹æ”¿ç­–ææ¡ˆ'

    # ç¦ç¥‰é–¢é€£
    if any(keyword in content for keyword in ['ç¦ç¥‰', 'ç¤¾ä¼šä¿éšœ', 'ä»‹è­·', 'éšœå®³è€…', 'é«˜é½¢è€…', 'ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ã‚¤ãƒ³ã‚«ãƒ ']):
        return 'ç¦ç¥‰', 'ç¤¾ä¼šä¿éšœåˆ¶åº¦ã‚„ç¦ç¥‰æ”¿ç­–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # åŒ»ç™‚é–¢é€£
    if any(keyword in content for keyword in ['åŒ»ç™‚', 'å¥åº·', 'ç—…é™¢', 'è¨ºç™‚', 'è–¬']):
        return 'åŒ»ç™‚', 'åŒ»ç™‚åˆ¶åº¦ã‚„å¥åº·æ”¿ç­–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # è¡Œæ”¿æ”¹é©é–¢é€£
    if any(keyword in content for keyword in ['è¡Œæ”¿', 'ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–', 'dx', 'æ‰‹ç¶šã', 'ç”³è«‹', 'æ¤œå', 'åŠ¹ç‡åŒ–']):
        return 'è¡Œæ”¿æ”¹é©', 'è¡Œæ”¿æ‰‹ç¶šãã®æ”¹é©ã‚„ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ãƒ‡ã‚¸ã‚¿ãƒ«æ°‘ä¸»ä¸»ç¾©é–¢é€£
    if any(keyword in content for keyword in ['æ°‘ä¸»ä¸»ç¾©', 'æ”¿æ²»å‚åŠ ', 'é€æ˜æ€§', 'è­°å“¡', 'é¸æŒ™', 'èª¤å ±å¯¾ç­–']):
        return 'ãƒ‡ã‚¸ã‚¿ãƒ«æ°‘ä¸»ä¸»ç¾©', 'æ”¿æ²»å‚åŠ ã‚„æ°‘ä¸»ä¸»ç¾©ã®ç™ºå±•ã«é–¢ã™ã‚‹ææ¡ˆ'

    # çµŒæ¸ˆè²¡æ”¿é–¢é€£
    if any(keyword in content for keyword in ['çµŒæ¸ˆ', 'è²¡æ”¿', 'ç¨', 'äºˆç®—', 'ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹', 'å¯è¦–åŒ–']):
        return 'çµŒæ¸ˆè²¡æ”¿', 'çµŒæ¸ˆæ”¿ç­–ã‚„è²¡æ”¿åˆ¶åº¦ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢é€£
    if any(keyword in content for keyword in ['ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'é›»åŠ›', 'åŸå­åŠ›', 'å†ç”Ÿå¯èƒ½']):
        return 'ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'ã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ç”£æ¥­æ”¿ç­–é–¢é€£
    if any(keyword in content for keyword in ['ç”£æ¥­', 'è¾²æ¥­', 'è£½é€ æ¥­', 'ãƒ“ã‚¸ãƒã‚¹']):
        return 'ç”£æ¥­æ”¿ç­–', 'ç”£æ¥­æŒ¯èˆˆã‚„è¾²æ¥­æ”¿ç­–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ç§‘å­¦æŠ€è¡“é–¢é€£
    if any(keyword in content for keyword in ['ç§‘å­¦', 'æŠ€è¡“', 'ai', 'äººå·¥çŸ¥èƒ½', 'ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼']):
        return 'ç§‘å­¦æŠ€è¡“', 'ç§‘å­¦æŠ€è¡“æ”¿ç­–ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ãƒ“ã‚¸ãƒ§ãƒ³é–¢é€£
    if any(keyword in content for keyword in ['ãƒ“ã‚¸ãƒ§ãƒ³', 'å°†æ¥', 'æ–¹å‘æ€§', 'é“ç­‹', 'æ–‡åŒ–ç«‹å›½']):
        return 'ãƒ“ã‚¸ãƒ§ãƒ³', 'å›½å®¶ãƒ“ã‚¸ãƒ§ãƒ³ã‚„å°†æ¥æ§‹æƒ³ã«é–¢ã™ã‚‹ææ¡ˆ'

    # ãã®ä»–
    return 'ãã®ä»–æ”¿ç­–', 'ä¸Šè¨˜ã‚«ãƒ†ã‚´ãƒªã«è©²å½“ã—ãªã„æ”¿ç­–ææ¡ˆ'


def main():
    print("ğŸ“Š æœªå‡¦ç† PR ã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")

    # YAML ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    data = load_yaml_data()

    # æœªå‡¦ç† PR ã‚’å–å¾—ï¼ˆä¸Šä½80ä»¶ï¼‰
    unprocessed_prs = get_unprocessed_prs(data, 80)
    print(f"ğŸ” åˆ†æå¯¾è±¡: {len(unprocessed_prs)} ä»¶ã®æœªå‡¦ç† PR")

    # åˆ†æçµæœã‚’ä¿å­˜
    analysis_results = []

    for i, pr in enumerate(unprocessed_prs, 1):
        pr_number = pr['number']
        print(f"ğŸ“ [{i:2d}/80] PR #{pr_number} ã‚’åˆ†æä¸­...")

        # PR è©³ç´°æƒ…å ±ã‚’å–å¾—
        pr_details = get_pr_details(pr_number)
        if not pr_details:
            continue

        # åˆ†é¡ã‚’å®Ÿè¡Œ
        new_label, analysis_notes = classify_pr(pr_details)

        analysis_results.append({
            'number': pr_number,
            'title': pr['title'],
            'new_label': new_label,
            'analysis_notes': analysis_notes,
            'classification_reason': f"ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æœ¬æ–‡ãƒ»å·®åˆ†ã‚’åˆ†æã—ãŸçµæœã€{new_label}åˆ†é‡ã®æ”¿ç­–ææ¡ˆã¨åˆ¤å®š"
        })

        print(f"   âœ… åˆ†é¡: {new_label} - {analysis_notes}")

        # API ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        time.sleep(0.5)

    # çµæœã‚’ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open('pr_analysis_results.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ åˆ†æå®Œäº†ï¼çµæœã‚’ pr_analysis_results.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    label_counts = {}
    for result in analysis_results:
        label = result['new_label']
        label_counts[label] = label_counts.get(label, 0) + 1

    print("\nğŸ“ˆ åˆ†é¡çµæœçµ±è¨ˆ:")
    for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  {label}: {count}ä»¶")


if __name__ == "__main__":
    main()
